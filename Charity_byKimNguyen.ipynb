{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThiKimKhue/deep-learning-challenge/blob/main/Charity_byKimNguyen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WSvKQgfy2Fj"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Y0_QDF9qy2Fm",
        "outputId": "82bdfa02-a2a5-405d-ebcb-39c77b4e7ca4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import pandas and read the charity_data.csv from the provided cloud URL.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zpl9eXBqy2Fp"
      },
      "outputs": [],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop([\"EIN\", \"NAME\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "9S7NYXT4y2Fq",
        "outputId": "83b0acc9-d127-4de3-f50f-e03282f4fd9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "wD7YQhCry2Fr",
        "outputId": "f335c3f8-42fb-40fc-970c-a7aa16d2049b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APPLICATION_TYPE\n",
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
        "application_counts=application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "application_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "f7MsOVkUy2Fs",
        "outputId": "63daf185-cd84-4bf3-9341-7ba906ce3ed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APPLICATION_TYPE\n",
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = list(application_counts[application_counts < 500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "fWGrQDhfy2Fu",
        "outputId": "088c4c14-dd52-4aa8-a2bb-03f62a14db94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: count, Length: 71, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jCHbbRj_y2Fu",
        "outputId": "e51e5f9d-de66-448a-f48c-e3ea9515218d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1238       10\n",
              "C1278       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C2400        6\n",
              "C1720        6\n",
              "C4100        6\n",
              "C1257        5\n",
              "C1600        5\n",
              "C1260        3\n",
              "C2710        3\n",
              "C0           3\n",
              "C3200        2\n",
              "C1234        2\n",
              "C1246        2\n",
              "C1267        2\n",
              "C1256        2\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "filtered_classification = class_counts[class_counts > 1]\n",
        "filtered_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "t2wiF-Y6pBvG",
        "outputId": "63b581db-77dc-4266-9671-84b8ccf8fbc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Let's check Pandas built-in graphing\n",
        "application_df[\"CLASSIFICATION\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "aAJ6LvWcqIp4",
        "outputId": "c886819b-8232-472b-843b-6b892faf2441"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='CLASSIFICATION', ylabel='Count'>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Let's try Hist plot with Seaborn for a better look\n",
        "import seaborn as sns\n",
        "sns.histplot(data=application_df, x='CLASSIFICATION')\n",
        "\n",
        "# note: you can see after we bin, it still skews heavily towards the C10,000. It's problematic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "rPc4jCVEy2Fw",
        "outputId": "50b3887a-97a6-4ce9-cfd4-2809d9373e34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>1</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows  109 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0           1      5000              1                   False   \n",
              "1           1    108590              1                   False   \n",
              "2           1      5000              0                   False   \n",
              "3           1      6692              1                   False   \n",
              "4           1    142590              1                   False   \n",
              "...       ...       ...            ...                     ...   \n",
              "34294       1      5000              0                   False   \n",
              "34295       1      5000              0                   False   \n",
              "34296       1      5000              0                   False   \n",
              "34297       1      5000              1                   False   \n",
              "34298       1  36500179              0                   False   \n",
              "\n",
              "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
              "0                      True                 False                False   \n",
              "1                     False                 False                 True   \n",
              "2                     False                 False                False   \n",
              "3                     False                 False                 True   \n",
              "4                     False                 False                 True   \n",
              "...                     ...                   ...                  ...   \n",
              "34294                 False                 False                False   \n",
              "34295                 False                 False                False   \n",
              "34296                 False                 False                 True   \n",
              "34297                 False                 False                False   \n",
              "34298                 False                 False                 True   \n",
              "\n",
              "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
              "0                    False                False                False  ...   \n",
              "1                    False                False                False  ...   \n",
              "2                    False                 True                False  ...   \n",
              "3                    False                False                False  ...   \n",
              "4                    False                False                False  ...   \n",
              "...                    ...                  ...                  ...  ...   \n",
              "34294                 True                False                False  ...   \n",
              "34295                 True                False                False  ...   \n",
              "34296                False                False                False  ...   \n",
              "34297                False                 True                False  ...   \n",
              "34298                False                False                False  ...   \n",
              "\n",
              "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0                  False                   False                     False   \n",
              "1                   True                   False                     False   \n",
              "2                  False                   False                     False   \n",
              "3                  False                    True                     False   \n",
              "4                  False                   False                      True   \n",
              "...                  ...                     ...                       ...   \n",
              "34294              False                   False                     False   \n",
              "34295              False                   False                     False   \n",
              "34296              False                   False                     False   \n",
              "34297              False                   False                     False   \n",
              "34298              False                   False                     False   \n",
              "\n",
              "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                   False             False                   False   \n",
              "1                   False             False                   False   \n",
              "2                   False             False                   False   \n",
              "3                   False             False                   False   \n",
              "4                   False             False                   False   \n",
              "...                   ...               ...                     ...   \n",
              "34294               False             False                   False   \n",
              "34295               False             False                   False   \n",
              "34296               False             False                   False   \n",
              "34297               False             False                   False   \n",
              "34298               False              True                   False   \n",
              "\n",
              "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0                False              False                      True   \n",
              "1                False              False                      True   \n",
              "2                False              False                      True   \n",
              "3                False              False                      True   \n",
              "4                False              False                      True   \n",
              "...                ...                ...                       ...   \n",
              "34294            False              False                      True   \n",
              "34295            False              False                      True   \n",
              "34296            False              False                      True   \n",
              "34297            False              False                      True   \n",
              "34298            False              False                      True   \n",
              "\n",
              "       SPECIAL_CONSIDERATIONS_Y  \n",
              "0                         False  \n",
              "1                         False  \n",
              "2                         False  \n",
              "3                         False  \n",
              "4                         False  \n",
              "...                         ...  \n",
              "34294                     False  \n",
              "34295                     False  \n",
              "34296                     False  \n",
              "34297                     False  \n",
              "34298                     False  \n",
              "\n",
              "[34299 rows x 109 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies` (do OHE)\n",
        "application_with_dumies_df = pd.get_dummies(application_df)\n",
        "application_with_dumies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GveiZXchy2Fx",
        "outputId": "914ecf14-80d0-4edb-9b61-65697d7e6590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(34299, 108)\n",
            "(25724, 108)\n",
            "(8575, 108)\n"
          ]
        }
      ],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X=application_with_dumies_df.drop(['IS_SUCCESSFUL'], axis=1).values # It's input feature X\n",
        "y=application_with_dumies_df['IS_SUCCESSFUL'].values # It's target label\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) # train_test_split will issolate 25% of my data as a test set)\n",
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "9knBa1K5y2Fv",
        "outputId": "15c8982a-7aff-4166-de9a-aa5b18670735"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Other     1484\n",
              "C7000      777\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced??\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace = list(class_counts[class_counts < 500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CCYpmvmGy2Fx"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_BMOqZ2y2Fx"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ves8MCR-y2Fy",
        "outputId": "ee636c94-49cb-45b3-d257-233a5d04ad09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,900</span> \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,040</span> \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                    \u001b[38;5;34m10,900\u001b[0m \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                      \u001b[38;5;34m4,040\u001b[0m \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m41\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,981</span> (58.52 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,981\u001b[0m (58.52 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,981</span> (58.52 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,981\u001b[0m (58.52 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Model 1\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 = 100 # you can start larger and go smaller number\n",
        "hidden_nodes_layer2=40\n",
        "\n",
        "nn = tf.keras.models.Sequential() # this is the most basic neural network, which has a series of sequential operations\n",
        "\n",
        "# First hidden layer ( # dense hidden layer is the most baisc type of hidden layer in a neural network)\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer (b/c this is a binary classification task, need to use sigmoid function to get either 0 or 1 (sucessful or failed))\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rOOCgreHy2Fy"
      },
      "outputs": [],
      "source": [
        "# Compile the model (when combile, you should identify Loss function)\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75xuE1lqy2Fy",
        "outputId": "19b5e403-5f38-4d40-cd1c-dbe028a9d85b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6889 - loss: 0.6009\n",
            "Epoch 2/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7284 - loss: 0.5554  \n",
            "Epoch 3/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7338 - loss: 0.5458\n",
            "Epoch 4/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7296 - loss: 0.5505\n",
            "Epoch 5/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7290 - loss: 0.5515  \n",
            "Epoch 6/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7367 - loss: 0.5408\n",
            "Epoch 7/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7312 - loss: 0.5478\n",
            "Epoch 8/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7331 - loss: 0.5432\n",
            "Epoch 9/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7330 - loss: 0.5423\n",
            "Epoch 10/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7352 - loss: 0.5401\n",
            "Epoch 11/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7337 - loss: 0.5388\n",
            "Epoch 12/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5331\n",
            "Epoch 13/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7358 - loss: 0.5364\n",
            "Epoch 14/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5379\n",
            "Epoch 15/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5367  \n",
            "Epoch 16/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7431 - loss: 0.5305\n",
            "Epoch 17/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5380\n",
            "Epoch 18/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5378\n",
            "Epoch 19/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7338 - loss: 0.5406\n",
            "Epoch 20/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5359\n",
            "Epoch 21/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.5377  \n",
            "Epoch 22/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7370 - loss: 0.5392\n",
            "Epoch 23/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7418 - loss: 0.5325\n",
            "Epoch 24/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7413 - loss: 0.5358\n",
            "Epoch 25/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5353\n",
            "Epoch 26/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5354\n",
            "Epoch 27/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5343\n",
            "Epoch 28/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7374 - loss: 0.5368\n",
            "Epoch 29/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7483 - loss: 0.5278\n",
            "Epoch 30/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.5338\n",
            "Epoch 31/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5326\n",
            "Epoch 32/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5304\n",
            "Epoch 33/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5327\n",
            "Epoch 34/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5296\n",
            "Epoch 35/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7426 - loss: 0.5325\n",
            "Epoch 36/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7341 - loss: 0.5387\n",
            "Epoch 37/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5316\n",
            "Epoch 38/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.5283\n",
            "Epoch 39/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7445 - loss: 0.5268\n",
            "Epoch 40/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7348 - loss: 0.5378\n",
            "Epoch 41/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5313\n",
            "Epoch 42/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5268\n",
            "Epoch 43/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7454 - loss: 0.5265\n",
            "Epoch 44/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5314  \n",
            "Epoch 45/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7433 - loss: 0.5288\n",
            "Epoch 46/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.5276\n",
            "Epoch 47/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7365 - loss: 0.5346\n",
            "Epoch 48/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7473 - loss: 0.5237\n",
            "Epoch 49/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5325\n",
            "Epoch 50/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7397 - loss: 0.5327\n",
            "Epoch 51/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.5305  \n",
            "Epoch 52/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.5268\n",
            "Epoch 53/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5351\n",
            "Epoch 54/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.5268\n",
            "Epoch 55/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.5284\n",
            "Epoch 56/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.5339\n",
            "Epoch 57/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5280\n",
            "Epoch 58/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5357\n",
            "Epoch 59/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5280\n",
            "Epoch 60/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7454 - loss: 0.5268\n",
            "Epoch 61/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.5282\n",
            "Epoch 62/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7371 - loss: 0.5350\n",
            "Epoch 63/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7421 - loss: 0.5282\n",
            "Epoch 64/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5283\n",
            "Epoch 65/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5275\n",
            "Epoch 66/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5296\n",
            "Epoch 67/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.5340\n",
            "Epoch 68/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.5290\n",
            "Epoch 69/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7438 - loss: 0.5245\n",
            "Epoch 70/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.5288\n",
            "Epoch 71/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7407 - loss: 0.5272\n",
            "Epoch 72/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5280\n",
            "Epoch 73/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7447 - loss: 0.5259  \n",
            "Epoch 74/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.5258\n",
            "Epoch 75/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7448 - loss: 0.5255\n",
            "Epoch 76/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7407 - loss: 0.5296\n",
            "Epoch 77/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7443 - loss: 0.5251\n",
            "Epoch 78/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7460 - loss: 0.5255\n",
            "Epoch 79/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5257\n",
            "Epoch 80/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5267\n",
            "Epoch 81/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7392 - loss: 0.5294\n",
            "Epoch 82/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7461 - loss: 0.5268\n",
            "Epoch 83/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5235  \n",
            "Epoch 84/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7406 - loss: 0.5266\n",
            "Epoch 85/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5293\n",
            "Epoch 86/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7427 - loss: 0.5264\n",
            "Epoch 87/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7446 - loss: 0.5258\n",
            "Epoch 88/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.5265\n",
            "Epoch 89/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7435 - loss: 0.5273\n",
            "Epoch 90/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.5290\n",
            "Epoch 91/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5247\n",
            "Epoch 92/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.5285\n",
            "Epoch 93/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5287\n",
            "Epoch 94/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7442 - loss: 0.5263\n",
            "Epoch 95/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.5237\n",
            "Epoch 96/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7431 - loss: 0.5278\n",
            "Epoch 97/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7439 - loss: 0.5256\n",
            "Epoch 98/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7426 - loss: 0.5254\n",
            "Epoch 99/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7405 - loss: 0.5328\n",
            "Epoch 100/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7416 - loss: 0.5275\n"
          ]
        }
      ],
      "source": [
        "# Train / fit the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dnaxQpvy2Fy",
        "outputId": "2d0d33dd-01ae-406f-af99-4254c2298349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - 1ms/step - accuracy: 0.7333 - loss: 0.5657\n",
            "Loss: 0.5657386779785156, Accuracy: 0.7332944869995117\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQsZg5B2y2Fy",
        "outputId": "45526512-9fb5-44e2-b84d-83edab61a9a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to 'AlphabetSoupCharity.h5'\n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('AlphabetSoupCharity.h5')\n",
        "print(\"Model saved to 'AlphabetSoupCharity.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bAdYtWaXGvud",
        "outputId": "51f6e5b0-c998-45ee-be16-4d8070edcd46"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Download the model file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      3\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlphabetSoupCharity.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Download the model file\n",
        "from google.colab import files\n",
        "files.download('AlphabetSoupCharity.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "j3cS-LYINQ6C",
        "outputId": "fb9e7100-38ff-4907-f28e-c567a88712e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,080</span> \n",
              "\n",
              " dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,680</span> \n",
              "\n",
              " dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> \n",
              "\n",
              " dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_6 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                    \u001b[38;5;34m13,080\u001b[0m \n",
              "\n",
              " dense_7 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                      \u001b[38;5;34m9,680\u001b[0m \n",
              "\n",
              " dense_8 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                      \u001b[38;5;34m2,430\u001b[0m \n",
              "\n",
              " dense_9 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m31\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,221</span> (98.52 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,221\u001b[0m (98.52 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,221</span> (98.52 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,221\u001b[0m (98.52 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Optimize the Model 2\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 = 120 # you can start larger and go smaller number\n",
        "hidden_nodes_layer2=80\n",
        "hidden_nodes_layer3=30\n",
        "\n",
        "nn = tf.keras.models.Sequential() # this is the most basic neural network, which has a series of sequential operations\n",
        "\n",
        "# First hidden layer ( # dense hidden layer is the most baisc type of hidden layer in a neural network)\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# 3rd hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "\n",
        "# Output layer (b/c this is a binary classification task, need to use sigmoid function to get either 0 or 1 (sucessful or failed))\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ua3HHr0NOHKl"
      },
      "outputs": [],
      "source": [
        "# Compile the model (when combile, you should identify Loss function)\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGiUETPFOb7E",
        "outputId": "ca3543d3-9dd7-4318-b3ea-52d819aa18a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7080 - loss: 0.5887\n",
            "Epoch 2/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7232 - loss: 0.5564\n",
            "Epoch 3/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7277 - loss: 0.5510\n",
            "Epoch 4/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7324 - loss: 0.5474\n",
            "Epoch 5/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5410\n",
            "Epoch 6/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7326 - loss: 0.5454\n",
            "Epoch 7/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7267 - loss: 0.5475\n",
            "Epoch 8/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7338 - loss: 0.5439\n",
            "Epoch 9/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5425\n",
            "Epoch 10/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7367 - loss: 0.5404\n",
            "Epoch 11/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.5389\n",
            "Epoch 12/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7379 - loss: 0.5364\n",
            "Epoch 13/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7322 - loss: 0.5467\n",
            "Epoch 14/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7337 - loss: 0.5396\n",
            "Epoch 15/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.5348\n",
            "Epoch 16/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7359 - loss: 0.5407\n",
            "Epoch 17/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.5411\n",
            "Epoch 18/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7399 - loss: 0.5356\n",
            "Epoch 19/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.5317\n",
            "Epoch 20/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7334 - loss: 0.5410\n",
            "Epoch 21/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5361\n",
            "Epoch 22/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5356\n",
            "Epoch 23/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7413 - loss: 0.5323\n",
            "Epoch 24/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7382 - loss: 0.5355\n",
            "Epoch 25/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5390\n",
            "Epoch 26/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7367 - loss: 0.5375\n",
            "Epoch 27/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7404 - loss: 0.5353\n",
            "Epoch 28/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5294\n",
            "Epoch 29/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7386 - loss: 0.5344\n",
            "Epoch 30/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7448 - loss: 0.5264\n",
            "Epoch 31/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7439 - loss: 0.5309\n",
            "Epoch 32/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.5299\n",
            "Epoch 33/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.5331\n",
            "Epoch 34/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7400 - loss: 0.5350\n",
            "Epoch 35/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7418 - loss: 0.5303\n",
            "Epoch 36/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7421 - loss: 0.5301\n",
            "Epoch 37/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7431 - loss: 0.5299\n",
            "Epoch 38/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7427 - loss: 0.5287\n",
            "Epoch 39/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7408 - loss: 0.5323\n",
            "Epoch 40/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7418 - loss: 0.5285\n",
            "Epoch 41/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7429 - loss: 0.5290\n",
            "Epoch 42/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7404 - loss: 0.5311\n",
            "Epoch 43/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5260\n",
            "Epoch 44/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5314\n",
            "Epoch 45/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5342\n",
            "Epoch 46/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.5286\n",
            "Epoch 47/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7388 - loss: 0.5329\n",
            "Epoch 48/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5257\n",
            "Epoch 49/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.5317\n",
            "Epoch 50/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7433 - loss: 0.5263\n",
            "Epoch 51/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5228\n",
            "Epoch 52/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7471 - loss: 0.5261\n",
            "Epoch 53/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.5282\n",
            "Epoch 54/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7399 - loss: 0.5308\n",
            "Epoch 55/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7420 - loss: 0.5310\n",
            "Epoch 56/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5269\n",
            "Epoch 57/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7476 - loss: 0.5223\n",
            "Epoch 58/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.5271\n",
            "Epoch 59/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7433 - loss: 0.5288\n",
            "Epoch 60/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.5226\n",
            "Epoch 61/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7429 - loss: 0.5278\n",
            "Epoch 62/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7433 - loss: 0.5249\n",
            "Epoch 63/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5254\n",
            "Epoch 64/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7369 - loss: 0.5311\n",
            "Epoch 65/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5221\n",
            "Epoch 66/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.5258\n",
            "Epoch 67/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7447 - loss: 0.5235\n",
            "Epoch 68/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7401 - loss: 0.5295\n",
            "Epoch 69/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.5248\n",
            "Epoch 70/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.5241\n",
            "Epoch 71/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7453 - loss: 0.5255\n",
            "Epoch 72/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7436 - loss: 0.5245\n",
            "Epoch 73/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7419 - loss: 0.5264\n",
            "Epoch 74/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7479 - loss: 0.5214\n",
            "Epoch 75/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7486 - loss: 0.5203\n",
            "Epoch 76/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.5264\n",
            "Epoch 77/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7452 - loss: 0.5242\n",
            "Epoch 78/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7415 - loss: 0.5263\n",
            "Epoch 79/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7472 - loss: 0.5201\n",
            "Epoch 80/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5215\n",
            "Epoch 81/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7426 - loss: 0.5285\n",
            "Epoch 82/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5249\n",
            "Epoch 83/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7453 - loss: 0.5213\n",
            "Epoch 84/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5222\n",
            "Epoch 85/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7436 - loss: 0.5231\n",
            "Epoch 86/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7415 - loss: 0.5259\n",
            "Epoch 87/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7443 - loss: 0.5237\n",
            "Epoch 88/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.5240\n",
            "Epoch 89/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7407 - loss: 0.5250\n",
            "Epoch 90/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5289\n",
            "Epoch 91/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7448 - loss: 0.5237\n",
            "Epoch 92/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5280\n",
            "Epoch 93/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7429 - loss: 0.5249\n",
            "Epoch 94/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7441 - loss: 0.5292\n",
            "Epoch 95/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7450 - loss: 0.5241\n",
            "Epoch 96/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7465 - loss: 0.5203\n",
            "Epoch 97/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.5255\n",
            "Epoch 98/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.5282\n",
            "Epoch 99/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5251\n",
            "Epoch 100/100\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7421 - loss: 0.5255\n"
          ]
        }
      ],
      "source": [
        "# Train / fit the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "igSqRDWnHWmP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - 1ms/step - accuracy: 0.7291 - loss: 0.5986\n",
            "Loss: 0.598561704158783, Accuracy: 0.7290962338447571\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IIH4Fq78HchF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to 'AlphabetSoupCharity_Optimization2.h5'\n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('AlphabetSoupCharity_Optimization2.h5')\n",
        "print(\"Model saved to 'AlphabetSoupCharity_Optimization2.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "b1wACvafOwFK"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Download the model file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      3\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlphabetSoupCharity_Optimization2.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Download the model file\n",
        "from google.colab import files\n",
        "files.download('AlphabetSoupCharity_Optimization2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Y4l3KZ1THlBl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">32,700</span> \n",
              "\n",
              " dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> \n",
              "\n",
              " dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> \n",
              "\n",
              " dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_14 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                    \u001b[38;5;34m32,700\u001b[0m \n",
              "\n",
              " dense_15 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                    \u001b[38;5;34m30,100\u001b[0m \n",
              "\n",
              " dense_16 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                      \u001b[38;5;34m1,010\u001b[0m \n",
              "\n",
              " dense_17 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m11\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,821</span> (249.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,821\u001b[0m (249.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,821</span> (249.30 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,821\u001b[0m (249.30 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Optimize the Model 3\n",
        "# Define the model\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 = 300\n",
        "hidden_nodes_layer2=100\n",
        "hidden_nodes_layer3=10\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Bbc9AV39Hlcl"
      },
      "outputs": [],
      "source": [
        "# Compile the model (when combile, you should identify Loss function)\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MSPzu2iSHlgL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7096 - loss: 0.5837\n",
            "Epoch 2/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7276 - loss: 0.5525\n",
            "Epoch 3/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7340 - loss: 0.5488\n",
            "Epoch 4/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5464\n",
            "Epoch 5/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7345 - loss: 0.5420\n",
            "Epoch 6/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7342 - loss: 0.5459\n",
            "Epoch 7/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7296 - loss: 0.5485\n",
            "Epoch 8/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5389\n",
            "Epoch 9/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7352 - loss: 0.5398\n",
            "Epoch 10/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5385\n",
            "Epoch 11/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5374\n",
            "Epoch 12/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7322 - loss: 0.5425\n",
            "Epoch 13/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 0.5381\n",
            "Epoch 14/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7356 - loss: 0.5408\n",
            "Epoch 15/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7332 - loss: 0.5424\n",
            "Epoch 16/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.5428\n",
            "Epoch 17/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7344 - loss: 0.5425\n",
            "Epoch 18/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7360 - loss: 0.5342\n",
            "Epoch 19/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.5397\n",
            "Epoch 20/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7391 - loss: 0.5342\n",
            "Epoch 21/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5332\n",
            "Epoch 22/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.5378\n",
            "Epoch 23/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7378 - loss: 0.5326\n",
            "Epoch 24/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.5335\n",
            "Epoch 25/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7363 - loss: 0.5397\n",
            "Epoch 26/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5338\n",
            "Epoch 27/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.5313\n",
            "Epoch 28/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5308\n",
            "Epoch 29/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: 0.5332\n",
            "Epoch 30/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5317\n",
            "Epoch 31/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5319\n",
            "Epoch 32/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.5318\n",
            "Epoch 33/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5296\n",
            "Epoch 34/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7413 - loss: 0.5293\n",
            "Epoch 35/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5280\n",
            "Epoch 36/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7439 - loss: 0.5298\n",
            "Epoch 37/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7406 - loss: 0.5251\n",
            "Epoch 38/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7410 - loss: 0.5280\n",
            "Epoch 39/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7404 - loss: 0.5299\n",
            "Epoch 40/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7403 - loss: 0.5313\n",
            "Epoch 41/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5258\n",
            "Epoch 42/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 0.5290\n",
            "Epoch 43/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7366 - loss: 0.5332\n",
            "Epoch 44/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7381 - loss: 0.5316\n",
            "Epoch 45/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7371 - loss: 0.5316\n",
            "Epoch 46/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5330\n",
            "Epoch 47/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7437 - loss: 0.5248\n",
            "Epoch 48/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5316\n",
            "Epoch 49/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7396 - loss: 0.5301\n",
            "Epoch 50/50\n",
            "\u001b[1m804/804\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.5346\n"
          ]
        }
      ],
      "source": [
        "# Train / fit the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kJIptbvkHlju"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - 1ms/step - accuracy: 0.7292 - loss: 0.5713\n",
            "Loss: 0.5712783932685852, Accuracy: 0.7292128205299377\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Y7GAFBkvHlmv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to 'AlphabetSoupCharity_Optimization3.h5'\n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('AlphabetSoupCharity_Optimization3.h5')\n",
        "print(\"Model saved to 'AlphabetSoupCharity_Optimization3.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "AIxEuGdpPFgd"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Download the model file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      3\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlphabetSoupCharity_Optimization3.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Download the model file\n",
        "from google.colab import files\n",
        "files.download('AlphabetSoupCharity_Optimization3.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
